Reading and Reflection

This paper talks about how machine translation has changed over time, starting from basic rules to more advanced methods like using examples, statistics, and neural networks.

These methods are all about using information efficiently to understand and process language, kind of like how people do it. For example, it's like going from translating words one by one to understanding phrases, or improving translation models to consider things like word order and context.

To explain further, think of rule-based translation like a beginner learning a new language, starting with simple word substitutions and eventually progressing to using whole phrases. Statistical methods are like the learner building a language model over time. And neural machine translation is like becoming fluent in the language, where you can think and express yourself naturally, similar to a native speaker.

In research, sometimes simpler ideas work better. For example, the idea of an interlingua, a common language for translation, was thought of early on but wasn't practical back then. With advancements in technology, like neural networks, this idea has become more achievable and effective.

+ For the question a:
Image Recognition and Computer Vision use methods from basic feature extraction to advanced CNNs. Reinforcement Learning employs techniques like Q-learning and deep neural networks. Hybrid models combine traditional and deep learning in Image Recognition. Recent RL advances include model-based and meta-learning. Both fields demonstrate diverse approaches, from simple algorithms to complex architectures, reflecting AI's breadth.


+ For the question b:
Both RBMT and NMT involve encoding and decoding steps. In RBMT, encoding involves aligning the source text to specific linguistic rules, while decoding entails applying these rules to generate the target language output. Similarly, in NMT, encoding and decoding occur at a more complex and abstract level within a neural network architecture, often described as a black box due to its internal workings.

Additionally, both RBMT and NMT aim to mimic human language processing. RBMT achieves this by adhering to predefined rules created by humans, while NMT learns linguistic patterns and rules from data, akin to an "interlingua," or internal language representation, developed through training.

For the question c:

Rule-based systems can be tailored to specific domains or languages where linguistic rules are well-defined and straightforward. In fields like medicine, law, or finance, where accuracy is critical and language tends to be formalized, rule-based solutions may outperform neural or statistical methods.
And they are generally less resource-intensive compared to neural or statistical approaches, making them suitable for environments with limited computational resources or internet connectivity. This can be particularly advantageous in developing regions or for applications running on low-powered devices.